# Crónica del simposio SIRGAS 2022: Día 1

Llegué a Chile el Sábado 5. Fue un vuelo impecable en Aerolíneas Argentinas,
con tiempo atmosférico inmejorable, y con una vista privilegiada de la
cordillera hacia el final del viaje. Se preparaba una semana muy interesante,
donde la cordillera tendría su propio protagonismo como uno de los principales
desafíos para la implementación de los marcos de referencia que me trajeron a
chile.

Luego de un muy bienvenido Domingo de descanso, incluyendo una recorrida a pie
a la tarde por Santiago para conocer la zona donde me alojé, llegó el primer
día del simposio, el lunes 7 de noviembre. Subí al metro con el tiempo justo,
sorprendido de la puntualidad y alta frecuencia del servicio. Tan sorprendido
que no noté el detalle de que, a la mañana, no todos los trenes paran en todas
las estaciones. Así me pasé unas larguísimas 10 cuadras que me hicieron llegar
por la mitad de la primera charla.

El simposio comenzó con las charlas institucionales. Primero
[Sofía Nilo](https://ar.linkedin.com/in/sofía-nilo-crisóstomo-979b0723) nos
comentó sobre [UN-GGIM](https://ggim.un.org/) y el papel que juega SIRGAS con
ese comité.  Fue bueno ver remarcado que los resultados de cooperación en
nuestra región son muy sólidos y pueden hasta servir como ejemplo a nivel
global.  lugeo [Sonia
Alves-Costa](https://br.linkedin.com/in/sonia-costa-46366847/en), del IBGH y presidente de SIRGAS, expuso el estado en general de
SIRGAS y todos sus proyectos. Hizo especial énfasis  en dos aspectos técnicos.
En primer lugar están los esfuerzos que se llevan a cabo para compatibilizar
los sistemas de altura y las mediciones de gravedad regionales, con el objetivo
de poder colaborar en la materialización del
[IHRF](https://ggos.org/item/height-reference-frame/). En segundo lugar está el
procesamiento continuo de los datos GNSS, vinculados al marco de referencia
ITRF, mostrando que a lo largo del tiempo, con la adopción de las sucesivas
versiones de ITRF, la precisión de la red mejoró mucho. Esto alienta a la
adopción, pronta a realizarse, de
[ITRF2020](https://itrf.ign.fr/en/solutions/ITRF2020), y el reprocesamiento de
las observaciones históricas en ese marco.
[Los temas tratados son similares a la presentación que está en este link.](https://sirgas.ipgh.org/wp-content/uploads/2022/10/2022_17_10_SIRGAS_REFAG2022.pdf)

Siguieron las presentaciones de cada grupo de trabajo. En la presentación del
Grupo I, que coordina el procesamiento de las observaciones GNSS,
[José Antonio Tarrío](https://www.digeo.usach.cl/jose-antonio-tarrio-mosquera),
de USACH, nos contó los avances y dificultades de la coordinación de esta
tarea. Se destacó la gran coherencia del procesamiento con los estándares
actuales, la inclusión de un nuevo centro de procesamiento en Costa Rica, y
varias situaciones puntuales con algunas estaciones que presentan dificultades
y se están analizando caso a caso para poder mejorar sus resultados. Resulta
muy alentador ver la gran organización del trabajo y cómo se coopera en todos
los detalles para lograr un procesamiento colaborativo coherente y de gran
precisión.

En la presentación del Grupo II,
[Demián Gómez](https://earthsciences.osu.edu/people/gomez.124), de OSU e
IGN Argentina, presentó los avances en la difícil tarea de fomentar el uso de
SIRGAS como marco de referencia en los diferentes paises miembro. Para eso
llevaron adelante diversas actividades de difusión, sondeo, capacitación, etc.

A este punto ya teníamos claro uno de los puntos importantes para ambos grupos
de trabajo, conseguir densificar la red SIRGAS-CON y mejorar la distribución
geográfica de estaciones. Consiguiendo así facilitar el procesamiento y la
validación de los resultados. Se habló de generar convenios para instalar
estaciones, y quedó en claro que SIRGAS es ante todo un gran esfuerzo de
cooperación

El Grupo III, presentado por [Gabriel
Guimarães](http://lattes.cnpq.br/3906104650421300), nos puso al tanto de los trabajos relativos a sistemas de altura y
mediciones gravimétricas. Nos contó de las capacitaciones y esfuerzos
realizados para poder establecer estaciones del IHRF en cada país miembro y de
los distintos esfuerzos para compartir y procesar datos gravimétricos. Aquí se
mencionó por primera vez uno de los temas que más me llamó la atención en el
simposio: el experimento del colorado.

Con la cabeza puesta en mi charla del martes, me quedaron dando vuelta en la
cabeza algunos conceptos de este primer bloque. Por un lado la existencia de
estaciones problemáticas en el procesamiento del marco de referencia con causas
desconocidas. La descripción detallada y estandarizada de los procesamientos y
el esfuerzo por construir alternativas que permitan la validación de los
resultados son dos puntos que tengo que tratar en la charla, y que están
íntimamente relacionados a la aparición de datos que no encajan.  Por otro
lado, algunos problemas para repetir resultados que aparecieron en la charla
del Grupo III también me llevan al tema de mi exposición: la reproducibilidad.

Llegó entonces el momento de la pausa para almorzar. Decidí caminar un rato por
santiago en lugar de comer en el IGN, digamos que preferí el caos por sobre la
organización.

Luego de una recorrida de dos horas por el centro, visitando el palacio de la
moneda, la plaza de armas, etc. Volví a tomarme el metro, esta vez sin peligro
de pasarme, y llegué nuevamente al IGN ya comenzada la primera charla de la
tarde. Nuevamente fallé en la puntualidad.

[Michael Craymer](https://mcraymer.github.io/) nos puso al tanto del [ISO
Geodetic Registry](https://geodetic.isotc211.org/), un registro de información
geodésica sobre sistemas de coordenadas y marcos de referencia, construido
siguiendo estándares ISO, y basado únicamente en información oficial, siendo un
apoyo importante para comunicar en forma coherente las propiedades de cualquier
dato geográfico. Y apareció una mención que nuevamente me llevó a querer
agregar un paréntesis a mi tema: data model. Evidentemente es importante crear
modelos de descripción de los datos y procesos que manejamos. No soy el único
que lo piensa, ¡bien por eso, debo estar encaminado!

Luego de una nueva charla sobre UN-GGIM que nos brindó [Daniel
Roman](https://www.gim-international.com/content/author/daniel-roman), de la
FIG, vinieron dos interesantes charlas sobre centros de procesamiento de datos
GNSS. Por un lado José Antonio Tarrío nos contó sobre el funcionamiento del
[centro de procesamiento en la
USACH](http://www.geomensura.usach.cl/centro-de-procesamiento-y-analisis-geodesico-usc),
una iniciativa universitaria sumamente interesante, que además de aportar a
SIRGAS aporta activamente al mantenimiento del marco de referencia nacional en
Chile y realizó desarrollos muy importantes para solucionar las dificultades
que las particularidades de la tectónica andina le traen a la geodesia chilena.
Por otro lado, [Alvaro Álvarez
Calderón](https://www.researchgate.net/profile/Alvaro-Alvarez-Calderon) nos
contó del nuevo centro de procesamiento en Costa Rica, donde además de
establecer una rutina de procesamiento con el software Bernesse estuvieron
haciendo capacitaciones sobre GAMIT.

Hablé personalmente con Álvaro después de su charla y me quedé gratamente
impresionado de su empuje y las ganas de implementar nuevas rutinas de cálculo,
consciente de la importancia de poder comparar entre distintos métodos,
software, etc. Nuevamente mi cabeza vuelve a la charla del martes, no soy el
único que piensa que es importante poder sabe qué hace exactamente un
procesamiento y cómo de comparable es con otros.

Antes de irnos al Café escuchamos a
[https://www.researchgate.net/profile/Youssef-Tawk](Youssef Tawk), de Leica
Geosystems, contarnos cómo funciona la detección y mitigación de interferencias
en los nuevos receptores Leica. Interesante, aunque desde el lado del usuario
no podemos hacer nada contra la interferencia más que intentar mejorar la
ubicación de las antentas.

Aproveché el café para hablar con algunos conocidos como Virginia Mackern y
Hernan Guagni, aunque sobre cada uno de ellos supongo que hablaré cuando
escriba sobre sus charlas de los días que quedan del simposio.

En el último bloque tuvimos varias charlas interesantes. En primer lugar la
charla de Ben Kurtz (se me dificulta recordar la cara y no encuentro
información en internet para dar un link, perdón), comparando la precisión que
se logra con distintos tiempos de ocupación en el procesamiento PPP con
distintos servicios on-line en Bolivia. La comparación puede parecer un trabajo
rutinario, pero es interesante realizar este tipo de comparaciones porque se
plantean preguntas interesantes sobre la utilidad de nuevos tipos de servicio
para viejas aplicaciones en la agrimensura.

Después de esto siguieron dos trabajos que me resultaron sumamente
interesantes, el primero por su explícita mención a la probabilidad, que
siempre es bienvenida, y el segundo porque puede interpretarse también a la luz
de la probabilidad, y me hizo sentarme a pensar que, desde el punto de vista de
distribuciones de probabilidad y modelos estadísticos pueden formularse muchos
conceptos de la geodesia de forma que sea accesible para un publico mas amplio
--ADVERTENCIA: puede que esto sea un sesgo propio--.

Para entender ambos trabajos hay que tener presente que, si se considera a la
observación GNSS como un dato que informa sobre la geometría interna de la red
geodésica --posiciones relativas de los puntos--, el valor absoluto de la
posición y su evolución en el tiempo queda desconocido. Para salvar esta
dificultad se propone un modelo que describa la evolución temporal de las
posiciones, y luego se elige, de entre todas las soluciones posibles que bajo
ese modelo sean equivalentes, la que cumpla con alguna condición que nos
interese. En el caso más simple, si se resuelve un sistema de ecuaciónes
utilizando la
[pseudo-inversa](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse),
como estamos acostumbrados en cálculo de compensación -La famosa formula que
incluye $A^TPA$, aunque en el caso que hablamos algebraicamente es más difícil
la solución, justamente porque no existe un único punto sino un subespacio de
soluciones- , estamos pidiendo que de todas las soluciones posibles se elija
aquella en que la suma de los cuadrados de los parámetros sea menor (lo que se
conoce como regularización L2).

Definido una modelo para las posiciones medias (que puede ser variable en el
tiempo) de una red Geodésica, los residuos de las coordenadas pueden
considerarse distribuidos según una variable aleatoria normal multivariada.
Sin embargo, dependiendo de los procesos físicos a los que está sometida la
red, y de las precisiones que se alcancen en la observación, puede ser que en
diversas situaciones un modelo en particular muestre residuos que no parezcan
seguir la distribución supuesta. De este principio parten los dos trabajos que
mencionaba, el primero en forma deliberada, y el segundo también si lo miramos
con atención.

Si realmente les interesan estos temas como a mi, recomiendo [este paper de
Sillard y Boucher]( https://doi.org/10.1007/s001900100166), Y por supuesto
algún libro sobre modelos lineales, no tengo presente ahora, pero [Internet
debe saber mejor que
yo.](https://duckduckgo.com/?q=libro+modelos+lineales+site:edu+-site:academia.edu&ia=web&kl=)

Y ahora retomando la crónica, vino la muy interesante charla donde
[https://cl.linkedin.com/in/felipe-carvajal-rodr%C3%ADguez-87141493](Felipe
Carvajal) nos mostró un método que, aplicando una teoría derivada del test de
hipótesis estadístico, se puede construir un proceso completamente automatizado
para decidir si una red GNSS sufre deformación de una época a otra.

Básicamente lo que plantea es que se puede comparar el mejor modelo que propone
que la red no está deformada contra el mejor modelo que propone que la red sí
está deformada, y que se debe aceptar el modelo deformado si la ventaja en
verosimilitud (coloquialmente es el poder explicativo del modelo), es
significativa.  El procedimiento sigue con un paso adaptativo para proponer
diversos modelos donde son distintos los conjuntos de estaciones que sufren
deformación.

La mención explícita a test de hipótesis y comparación de diversos modelos con
residuos gaussianos me deja considerando la importancia de tener siempre
presente que los métodos de cálculo que aplicamos en geodesia asumen
normalidad, y deberíamos plantearnos más seguido que nuestro modelo se aparta
de sus propios supuestos, y puede haber un modelo alternativo (u otra familia
de modelos), que explique significativamente mejor nuestros datos. Esto nos
lleva a la siguiente charla, donde se habló justamente de la necesidad de hacer
modificaciones al modelo que describe las posiciones geodésicas en ITRF para
mejorar el ajuste de los marcos de referencia regionales.

Fue entonces el turno de Demián Gómez, que nos presentó el procedimiento que se
utiliza para realizar el cálculo del marco de referencia argentino, POSGAR,
tanto en su versión operacional (definido semana a semana) como en su versión
de (re)procesamiento (que define trayectorias parametrizadas para los puntos).
La presentación siguió de cerca
[https://link.springer.com/article/10.1007/s00190-022-01594-0](este paper que
publicaron junto con otros autores) en journal of geodesy.

El concepto principal es el siguiente: Aunque bajo una mirada global ITRF no
presenta una rotación ni un movimiento conjunto que sea trivialmente
parametrizable (en términos de un modelo lineal con coeficientes comunes a
todas las estaciones por ejemplo) a lo largo del tiempo, no se puede asumir que
al tomar un sub-conjunto de posiciones se mantega esta propiedad.

En otras palabras, definido una modelo para las posiciones medias (que puede
ser variable en el tiempo) de la red global, los residuos de todas las
coordenadas de la red, eliminada esa media y mirados en conjunto, pueden
considerarse distribuidos según una variable aleatoria normal, que es
estacionaria (no varía las propiedades estadísticas en el tiempo). Sin embargo,
si se toma una sub-red, dependiendo de su configuración, puede perderse la
estacionaridad.

En caso de que sea este el caso
-[DESTRIPE](https://www.rae.es/observatorio-de-palabras/destripe): es-, puede
existir un modelo alternativo de las posiciones medias que haga que la el
proceso que describe los residuos de las posiciones sea estacionario tanto para
la red global como para la red local.

Considerando la metodología comúnmente usada en geodesia de aplicar
transformaciones de similaridad (conocidas como de Helmert) para compatibilizar
los modelos que describen las posiciones en dos marcos de referencia distintos
(uno "padre" y otro "hijo" en el lenguaje que proponen), la propuesta es que se
debe considerar en la medida de lo posible el mismo modelo para las posiciones
en ambos marcos de referencia. El ejemplo que dan es el que sigue: si ITRF14 no
considera componentes periódicas (anual y semi-anual) como parte de su modelo
de posiciones, pero POSGAR sí lo considera, se conseguirá una mejor coherencia
entre marcos si se agregan las componentes periódicas a ITRF antes de aplicar
la alineación, es decir se realiza la compatibilización utilizando modelos
iguales.

La transformación de similaridad no contradice nunca a las observaciones
geodésicas de la geometría interna de la red, sino que sólo afecta a la
estimación de los parámetros de los modelos de posición. Mientras los modelos
propuestos sean lineales en sus parámetros, puede aplicarse esta transformación
a cada conjunto de parámetros (por ejemplo posiciones, velocidades, amplitudes
de componentes periódicas Seno, amplitudes de componentes periódicas Coseno,
etc.) por separado, y en cada caso esto afectará a la evolución en el tiempo de
la red sin modificar su geometría interna.

Y ahora, antes de seguir con el resto de las charlas, quiero hacer una
reflexión sobre estas dos charlas, que caprichosamente agrupé y sobre las que
tanto me explayé -énfasis en "tanto"-. En ambos casos se está tratando con
problemas similares: selección de modelos. En la actualidad la precisión de las
observaciones geodésicas permite incluir determinados términos en los modelos
de posición que en el pasado no hubieran estado justificados.  Quiero decir, al
aplicar un estadístico adecuado para la selección de modelos, si el error de
medición es suficientemente alto, no se justifica elegir un modelo más
complejo, porque desde el punto de vista estadístico la información que se
quiere parametrizar es indistinguible del ruido. Los métodos de ajuste a los
que estamos acostumbrados suponen normalidad en los residuos, mientras que cada
mejora en el proceso de medición y procesamiento de datos nos aparta de ese
supuesto, obligándonos a hacer un trabajo de selección de nuevos modelos cada
vez. Por eso considero de mucha importancia para la geodesia (y por supuesto
para la agrimensura en general) hacer hincapié siempre que se pueda en la
importancia de la probabilidad, la estadística, y la influencia que esta tiene
en los métodos con los que trabajamos todos los días.

Dejando ahora el proselitismo de mis ideas sobre educación y matemática, sigo
contando las actividades del día.  Siguieron dos charlas sobre infraestructura
y logística del mantenimiento de los marcos de referencia. Estuvieron a cargo
de personal del Instituto Geográfico Militar de Ecuador y del Instituto
Geográfico Agustín Codazzi, de Colombia.  Pudimos nuevamente apreciar los
grandes esfuerzos de administración de recursos y logística que es necesario
hacer para materializar y mantener los marcos de referencia tanto geodésico
como de alturas. Nuevamente hubo muchas menciones a la colaboración entre
instituciones. Sumamente alentador.

Luego de un pequeño corte finalizaron las actividades del día con la reunión
del Grupo de Trabajo I. Se habló de la necesidad de implementar en forma
generalizada el uso de archivos RINEX 4 (que en el de observación son similares
al RINEX 3), para poder ser consistentes en el manejo de datos
multiconstelación.  Énfasis aquí en la necesidad de que los profesionales se
acostumbren al uso de estos archivos, al menos como intercambio -no sería
necesario que modifiquen sus flujos de trabajo, pero si que conozcan el
formato-. También se habló de las pruebas que se están haciendo para incorporar
Galileo a los procesamientos oficiales de SIRGAS, aunque hay diferencias según
qué órbitas se utilicen para procesar. Laura Sanchez (que va a aparecer en la
crónica del Martes, por sus charlas de la mañana) hizo mención al uso de
modelos de carga de no-marea, lo que se superpone en parte con la utilización
de componentes periódicas, aunque supongo que el problema quedará mejor
planteado al adoptar ITRF2020 que incluye componentes periódicas, quedando los
efectos modelables de carga no-marea como un residuo.  Finalmente se hicieron
algunos comentarios sobre estaciones que no pueden procesarse bien con uno u
otro software, y se manifestó que el GTI está trabajando para redistribuir el
procesamiento y solucionar esos problemas.

Al finalizar la reunión nos estaban esperando en la mapoteca del Instituto para
el Coctail, donde pudimos hacer un pequeño brindis y disfrutar de una muestra
de danza tradicional chilena (cueca) por parte de personal de Instituto
Geográfico Militar de Chile, que nos recibió y nos trató muy amablemente.

Finalizado el día de simposio, volví nuevamente al metro para regresar a mi
hotel.  Tenía que trasladarme a otro alojamiento porque había hecho mal la
reserva original y no me quedó más solución que pasar unas noches en un lugar y
las demás en otro, así que nuevamente volví al metro, esta vez con mi valija, y
pasé a mi nuevo alojamiento.  Cené en algún local frente al parque Bustamante,
y volví a mi habitación para preparar algunas notas para la charla del martes.
Al fin el sueño le ganó a los nervios, y hasta aquí la crónica del primer día
del simposio.

